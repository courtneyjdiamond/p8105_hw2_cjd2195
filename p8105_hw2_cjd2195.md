P8105 Homework 2
================
Courtney Diamond
09-26-2023

## Problem 1

First we’re going to load our tidyverse library and first dataset,
`pols_month.csv`.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    month = case_match(
      month,
      "01" ~ "January",
      "02" ~ "February",
      "03" ~ "March", 
      "04" ~ "April", 
      "05" ~ "May", 
      "06" ~ "June",
      "07" ~ "July",
      "08" ~ "August",
      "09" ~ "September", 
      "10" ~ "October", 
      "11" ~ "November", 
      "12" ~ "December",
    )
  ) |> 
  mutate(
    year = as.integer(year)
  ) |> 
  mutate(
    day = as.integer(day)
  ) |> 
  mutate(
    president =
      case_match(
        prez_gop,
        0 ~ "dem",
        1 ~ "rep"
      )
  ) |> 
  select(!prez_gop & !prez_dem & !day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_month_df
```

    ## # A tibble: 822 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

The first dataset, `pols_month_df`, contains information relating to the
political affiliations of elected federal leaders (Senate, House of
Representatives, and President) and state governors for each month of
each year since 1947 up to June of 2015. The cleaned dataset has a size
of 822 rows (observations) and 9 columns (variables), with key variables
including the following:

- `year` : the year of the observation
- `month` : the month of the observation
- `gov_gop` : the number of Republican governors
- `sen_gop` : the number of Republican Senators
- `rep_gop` : the number of Republican Representatives
- `gov_dem` : the number of Democratic governors
- `sen_dem` : the number of Democratic Senators
- `rep_dem` : the number of Democratic Representatives
- `president` : the affiliation of the US President (Republican or
  Democratic)

Now we’ll load the `snp` dataset. First though, I can see that we’ll
need to transform years from two digits to four, so I’m also going to
code in a vector that specifies which of the two-digit combinations
belong to this century in order to help make the conversion a little
easier. (I can do this because I know from reading the dataset
description that the data covers from the 1950s to present day; if this
were for 1900 up to present, I’d have to approach it differently.)

``` r
this_century_years = c(0:15)

snp_df = 
  read_csv("data/snp.csv") |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    month =
      case_match(
        month,
        "1" ~ "January",
        "2" ~ "February",
        "3" ~ "March",
        "4" ~ "April",
        "5" ~ "May",
        "6" ~ "June",
        "7" ~ "July",
        "8" ~ "August",
        "9" ~ "September",
        "10" ~ "October",
        "11" ~ "November",
        "12" ~ "December"
      )
  ) |> 
  mutate(
    year = as.integer(year)
  ) |> 
  mutate(
    year = if_else(year %in% this_century_years, year + 2000, year + 1900)
  ) |> 
  relocate(year, month) |> 
  select(!day)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month    close
    ##    <dbl> <chr>    <dbl>
    ##  1  2015 July     2080.
    ##  2  2015 June     2063.
    ##  3  2015 May      2107.
    ##  4  2015 April    2086.
    ##  5  2015 March    2068.
    ##  6  2015 February 2104.
    ##  7  2015 January  1995.
    ##  8  2014 December 2059.
    ##  9  2014 November 2068.
    ## 10  2014 October  2018.
    ## # ℹ 777 more rows

The second dataset, `snp_df`, contains information about the closing
value of the Standard and Poor’s stock index for each listed date.
Originally, the dataset had discrete dates listed for each value;
however, I have removed the day associated with the date, and now the
values associated are only those of year and month. This allowed me to
then merge this dataset with the one above, which did not have
day-specific data. The cleaned dataset has a size of 787 rows and 3
columns, ranging in dates from January of 1950 to July of 2015.
Variables include:

- `year` : the year of the observation
- `month` : the month of the observation
- `close` : the closing value of the S&P index

Now we’ll load the unemployment data.

``` r
unemp_df = 
  read_csv("data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "Month", 
    values_to = "unemp_pct"
  ) |> 
  mutate(
    Month = 
      case_match(
        Month, 
        "Jan" ~ "January",
        "Feb" ~ "February",
        "Mar" ~ "March",
        "Apr" ~ "April",
        "May" ~ "May",
        "Jun" ~ "June",
        "Jul" ~ "July",
        "Aug" ~ "August",
        "Sep" ~ "September",
        "Oct" ~ "October",
        "Nov" ~ "November",
        "Dec" ~ "December"
        )
  ) |> 
  rename(year = Year, month = Month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemp_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemp_pct
    ##    <dbl> <chr>         <dbl>
    ##  1  1948 January         3.4
    ##  2  1948 February        3.8
    ##  3  1948 March           4  
    ##  4  1948 April           3.9
    ##  5  1948 May             3.5
    ##  6  1948 June            3.6
    ##  7  1948 July            3.6
    ##  8  1948 August          3.9
    ##  9  1948 September       3.8
    ## 10  1948 October         3.7
    ## # ℹ 806 more rows

The last dataset, `unemp_df`, contains the unemployment rate measured as
a percentage for a given year and month. The cleaned dataset has a size
of 816 rows and 3 columns, and contains information from January 1948 up
to December of 2015 (though the last six months of December do not have
percentages listed.) The variables include:

- `year` : the year of the observation
- `month` : the month of the observation
- `unemp_pct` : the unemployment percentage in the US

Now we’ll merge the datasets, left-joining sequentially (which will
conesequently join observations by year and month.)

``` r
fivethreeeight_df = left_join(
  pols_month_df, snp_df
) |> 
  left_join(unemp_df)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
fivethreeeight_df
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 January      23      51     253      23      45     198 dem          NA
    ##  2  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  3  1947 March        23      51     253      23      45     198 dem          NA
    ##  4  1947 April        23      51     253      23      45     198 dem          NA
    ##  5  1947 May          23      51     253      23      45     198 dem          NA
    ##  6  1947 June         23      51     253      23      45     198 dem          NA
    ##  7  1947 July         23      51     253      23      45     198 dem          NA
    ##  8  1947 August       23      51     253      23      45     198 dem          NA
    ##  9  1947 Septem…      23      51     253      23      45     198 dem          NA
    ## 10  1947 October      23      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemp_pct <dbl>

The resultant dataset is size 822x11, with the following variables. Any
observations that are missing are denoted with `NA`.

- `year` : the year of the observation
- `month` : the month of the observation
- `gov_gop` : the number of Republican governors
- `sen_gop` : the number of Republican Senators
- `rep_gop` : the number of Republican Representatives
- `gov_dem` : the number of Democratic governors
- `sen_dem` : the number of Democratic Senators
- `rep_dem` : the number of Democratic Representatives
- `president` : the affiliation of the US President (Republican or
  Democratic)
- `close` : the closing value of the S&P index
- `unemp_pct` : the unemployment percentage in the US

## Problem 2

Let’s load the Mr. Trash Wheel dataset.

``` r
library(readxl)

mr_trash_wheel_df = 
  read_excel("data/Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N549") |> 
  janitor::clean_names() |> 
  mutate(
    houses_powered = (weight_tons * 500) / 30
  ) |> 
  select(!homes_powered) |> 
  mutate(
    trash_wheel = "Mr. Trash Wheel"
  ) |> 
  relocate(trash_wheel) |> 
  mutate(
    year = as.numeric(year)
  )

prof_trash_wheel_df = 
  read_excel("data/Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M96") |> 
  janitor::clean_names() |> 
  mutate(
    houses_powered = (weight_tons * 500) / 30
  ) |> 
  select(!homes_powered) |> 
  mutate(
    trash_wheel = "Prof. Trash Wheel"
  ) |> 
  relocate(trash_wheel)

gwynnda_trash_wheel_df = 
  read_excel("data/Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:K108") |> 
  janitor::clean_names() |> 
  mutate(
    houses_powered = (weight_tons * 500) / 30
  ) |> 
  select(!homes_powered) |> 
  mutate(
    trash_wheel = "Gwynnda Trash Wheel"
  ) |> 
  relocate(trash_wheel)



trash_wheel_data_df = bind_rows(
  mr_trash_wheel_df,
  prof_trash_wheel_df,
  gwynnda_trash_wheel_df
) |> 
  relocate(plastic_bags, .after = sports_balls)

trash_wheel_data_df
```

    ## # A tibble: 747 × 16
    ##    trash_wheel     dumpster month  year date                weight_tons
    ##    <chr>              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 737 more rows
    ## # ℹ 10 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   plastic_bags <dbl>, houses_powered <dbl>

Taking a moment to walk through all the above code: for each dataset, I
first imported the respective sheet from the Excel document using the
range I specified, created my own version of the `homes_powered`
variable using the formula described in the original dataset, removed
the old version of the `homes_powered` variable so as not to have
duplicates with my own, then added a column to the dataset specifying
which Trash Wheel the data belong to. Having done this, and assuring
myself that columns represented across multiple datasets were in the
same order and spelled the same, it was safe to use the `bind_rows`
function to join the datasets together. In a final step, I moved the
`plastic_bags` variable to come before the final `houses_powered`
variable because I wanted to keep similar variables (i.e. counts of
items found) grouped together.

The resulting dataset `trash_wheel_data_df` is 747 rows and 16 columns
in size, meaning there are 747 observations and 16 total variables. The
variables include:

- `trash_wheel` : which trash wheel the data come from
- `dumpster` : a unique identifier of the dumpster the data come from
- `month` : the month of the observation
- `year` : the year of the observation
- `date` : the date of the observation
- `weight_tons` : the weight of all the trash collected, in tons
- `volume_cubic_yards` : the volume of all the trash collected, in cubic
  yards
- `plastic_bottles` : the number of plastic bottles collected
- `polystyrene` : the number of polystyrene items collected
- `cigarette_butts` : the number of cigarette butts collected
- `glass_bottles` : the number of glass bottles collected
- `grocery_bags` : the number of grocery bags collected
- `chip_bags` : the number of chip bags collected
- `sports_balls` : the number of sports balls collected
- `plastic_bags` : the number of plastic bags collected (it is unknown
  if these are the same as “grocery bags”, so I have kept them as a
  separate variable)
- `houses_powered` : the number of homes able to be powered from the
  trash collected, based on the suggested calculation that each ton
  creates 500 kW and each home uses 30kW.

The total amount of weight collected by Prof. Trash Wheel is 190.12
tons.

The total number of cigarette butts collected by Gwynnda in July 2021 is
16300.
